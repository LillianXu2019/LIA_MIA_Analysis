---
title: "LIA_MIA_analysis"
author: "Yuyan Xu"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE)
```

# Source functions

```{r results='hide'}
source('Source/Setup.R')
source('Source/Functions.R')
```

```{r}
source('Source/ReadData.R')
```
# Descriptives 
## inspect missingness
### predictors
```{r}
list_predictors <- c("QUIC", "Digit_span", "Family_income")
```

### missing patterns
Note: the missing data graph tells us the observations that have missing values for each variable (single dots) and the observations that have missing values in multiple variables together (linked dots).  
Source: https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html

LIA data
```{r}
df_pred_LIA3 <- df_predictors %>% 
  filter(id %in% subset(gng_long, version == "third")$id) %>% 
  select(list_predictors)

print("Missing data for each variable in LIA - third version:")
df_pred_LIA3 %>% summarize_all(~ sum(is.na(.))) %>% glimpse()
df_pred_LIA3 %>% gg_miss_upset(.)

df_pred_LIA3 <- df_pred_LIA3 %>% na.omit()
paste("Sample size for LIA - third version predictors: ", nrow(df_pred_LIA3))
```

MIA data
```{r}
df_pred_MIA <- df_predictors %>% 
  filter(id %in% subset(gng_long, version == "MIA")$id) %>% 
  select(list_predictors)

print("Missing data for each variable in MIA:")
df_pred_MIA %>% summarize_all(~ sum(is.na(.))) %>% glimpse()
df_pred_MIA %>% gg_miss_upset(.)

df_pred_MIA <- df_pred_MIA %>% na.omit()
paste("Sample size for MIA predictors: ", nrow(df_pred_MIA))
```

## predictor summary
```{r}
print("LIA summary:")
df_pred_LIA3 %>% st(.)
print("MIA summary:")
df_pred_MIA %>% st(.)

# t-test
ttest_LIA <- df_pred_LIA3 %>% mutate(study = "LIA")
ttest_MIA <- df_pred_MIA %>% mutate(study = "MIA")
ttest <- rbind(ttest_LIA,ttest_MIA)

a <- nice_t_test(data = ttest, response = "QUIC", group = "study", alternative = "two.sided", var.equal = TRUE) 
b <- nice_t_test(data = ttest, response = "Digit_span", group = "study", alternative = "two.sided", var.equal = TRUE) 
c <- nice_t_test(data = ttest, response = "Family_income", group = "study", alternative = "two.sided", var.equal = TRUE) 

bind_rows(a, b, c)
rm(a, b, c, ttest_LIA, ttest_MIA, ttest)
```

## predictor correlations
The correlation between family income and QUIC is very different in LIA and MIA samples.
```{r}
print("LIA correltaion:")
ggpairs(df_pred_LIA3, title="") + theme_bw()
print("MIA correltaion:")
ggpairs(df_pred_MIA, title="") + theme_bw()
```

## learning curve plot
LIA 
image: ![](../plots/gonogo_task/third_cues.png)  

MIA 
image: ![](../plots/gonogo_task/MIA_cues.png)  

# GNG TASK

## prep data

cue (index.html line 263-275):\
0 = go to win\
1 = no go to win\
2 = go to maintain\
3 = no go to maintain

```{r}
# select variables to standardize
vars <- c('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress', 'Parent_child_conflict')

##################### long data #####################
df_gng_glmm <- left_join(gng_long, df_predictors, by = 'id') %>% 
  mutate(go_str = factor(go_nogo, levels=0:1, labels=c("no go", "go")),
         go_strR = relevel(go_str, ref = "go"), # relevel the reference level to "go" 
         val_str = factor(win_maintain, levels=0:1, labels=c("negative", "positive")),
         val_strR = relevel(val_str, ref = "positive"), # relevel the reference level to "positive" 
         nonswitch = factor(nonswitch, levels=0:1, labels=c("switch", "no switch")),
         phase = if_else(trial_num < 16, "first half", "second half") %>% as.factor,
         trial_num0 = trial_num - 1) %>% 
  filter_at(c('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress'), all_vars(!is.na(.))) %>%
  mutate_at(vars, ~(scale(.) %>% as.vector)) 

df_gng_glmm_LIA <- df_gng_glmm %>% filter(version == "third")
df_gng_glmm_MIA <- df_gng_glmm %>% filter(version == "MIA")
# paste("GNG task total N: ", n_distinct(gng_long$id))
paste0("After removing incomplete data in predicting variables ('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress'): ")
paste0("-- Monetary Reward (LIA) sample size - third version: ", n_distinct(df_gng_glmm_LIA$id))
paste0("-- Affective Reward (MIA) sample size: ", n_distinct(df_gng_glmm_MIA$id))
```

## covariates

```{r include=FALSE}
covariates = "Digit_span + Family_income + Perceived_stress"
paste0("Covariates: ", covariates)
```

### functions

```{r}
run_models <- function(study, covariates, model_setup) {
  if (study == "LIA") {data = df_gng_glmm_LIA} else {data = df_gng_glmm_MIA}
  for (i in 1:nrow(model_setup)) {
    mod_name <- paste0(model_setup[i, "mod_name"], study)
    print(mod_name)
    response <- model_setup[i, "response"]
    key_var <- model_setup[i, "key_var"]
    random_structure <- model_setup[i, "random_structure"]
    
    predictors = c(key_var, covariates, random_structure)
    mod <- model_fun(response, predictors, data)
    
    assign(mod_name, mod, envir = .GlobalEnv)
    saveRDS(get(mod_name), file.path(gng_dir, paste0("models/", mod_name, ".rds")))
  }
}

tidy_mod_fun <- function(model_list) {
  for (i in (1:length(model_list))) {
    name <- names(model_list)[[i]]
    mod <- model_list[[i]]
    
    if (class(mod) == "glmerMod") {
      table <- mod %>% tidy(conf.int = TRUE, exp = TRUE) 
    } else {
      table <- mod %>% tidy(conf.int = TRUE)
    }
    
    table <- table %>% mutate(name = name)
    summary <- bind_rows(summary, table)
  }
  return(summary)
}
```

### model specifications

```{r}
model_setup <- read_csv("mod_specs.csv")
```

### run models

```{r eval=FALSE}
run_models("LIA", covariates, model_setup)
run_models("MIA", covariates, model_setup)
```

### read in models

```{r}
# Make a vector of all your file paths
file_paths <- list.files(path = file.path(gng_dir, "models"), pattern = "\\.rds", full.names = TRUE)

# Make a vector of file names
file_names <-  gsub(pattern = "\\.rds$", replacement = "", x = basename(file_paths))

# Read all your data into a list
data_list <- lapply(file_paths, readRDS)

# Assign file names to list elements
names(data_list) <- file_names      
```

### summarize models

```{r}
summary <- tibble()
summary <- tidy_mod_fun(data_list) %>% 
  filter(!is.na(std.error)) %>% 
  select(-c(effect, group)) %>% 
  filter(str_detect(term, "QUIC"))
write_csv(summary, file.path(gng_dir, "model_summary.csv"))
```

### compare models

```{r eval=FALSE}
mod1_correctLIA <- readRDS(file.path(gng_dir, "models/mod1_correctLIA.rds"))
mod1_correct_polyLIA <- readRDS(file.path(gng_dir, "models/mod1_correct_polyLIA.rds"))
mod2_val_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctLIA.rds"))
mod2_val_correct_polyLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correct_polyLIA.rds"))

mod1_correctMIA <- readRDS(file.path(gng_dir, "models/mod1_correctMIA.rds"))
mod1_correct_polyMIA <- readRDS(file.path(gng_dir, "models/mod1_correct_polyMIA.rds"))
mod2_val_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctMIA.rds"))
mod2_val_correct_polyMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correct_polyMIA.rds"))
```

Across both LIA and MIA studies, models **without** the polynomial terms have lower AIC and BIC, indicating a better model fit.  

```{r eval=FALSE}
anova(mod1_correctLIA, mod1_correct_polyLIA)
anova(mod2_val_correctLIA, mod2_val_correct_polyLIA)

anova(mod1_correctMIA, mod1_correct_polyMIA)
anova(mod2_val_correctMIA, mod2_val_correct_polyMIA)
```

### plot models

```{r}
mod2_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_correctLIA.rds"))
mod2_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_correctMIA.rds"))
mod2_val_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctLIA.rds"))
mod2_val_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctMIA.rds"))
```

#### whether the accuracy for **go and nogo cues** vary with unpredictability?

##### Monetary reward (LIA)
```{r}
title = paste0("mod2_correctLIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_correctLIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

##### Affective reward (MIA)
```{r}
title = paste0("mod2_correctMIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_correctMIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

#### whether the accuracy for **Pos and Neg feedback** vary with unpredictability?

##### Monetary reward (LIA)
```{r}
title = paste0("mod2_val_correctLIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_val_correctLIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

##### Affective reward (MIA)
```{r}
title = paste0("mod2_val_correctMIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_val_correctMIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

## Across the entire task

### DV: Go

#### Mod1: Does unpredictability bias children's Go/NoGo response?

##### Monetary reward
```{r eval=FALSE}
random_structure = "(1 + trial_num0| id)"
predictors = c("QUIC*trial_num0", covariates, random_structure)
mod1_LIA <- model_fun("go", predictors, df_gng_glmm_LIA)
saveRDS(mod1_LIA, file.path(gng_dir, "models/mod1_LIA.rds"))

# # trial3 as a quadratic term
# # drop the polynomial term because that is not significant over and beyond the linear term
# random_structure = "(1 + poly(trial3,2,raw=FALSE)| id)"
# predictors = c("QUIC*poly(trial3,2,raw=FALSE)", covariates, random_structure)
# mod1_poly <- model_fun("go", predictors, df_gng_glmm)
# saveRDS(mod1_poly, file.path(gng_dir, "models/mod1_poly.rds"))

### note: with this sample size (n =54) cannot add in the polynomial term because the model won't converge.
### how to add in polynomial term to an interaction model? referred to this source: https://stackoverflow.com/questions/47372262/r-interactions-between-independent-variable-and-polynomial-term
```

```{r}
mod1_LIA <- readRDS(file.path(gng_dir, "models/mod1_LIA.rds"))
# summary(mod1_LIA)
tab_model(mod1_LIA)

(plot_model(mod1_LIA, type="emm",
            terms=c("trial_num0 [all]", "QUIC [-1, 1]"), 
            title = "LIA_go_QUIC*trial_num0",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"LIA_go_QUIC*trial_num0.png"), width = 15, height = 10, units = "cm")
```

```{r eval=FALSE}
# multiple comparison for interaction
# contrast 1
emmeans(mod1_LIA, pairwise ~ QUIC|trial_num0,  
        at = list(QUIC = c(-1, 1),
                  trial_num0 = c(0, 14, 29)))
# contrast 2
emmeans(mod1_LIA, pairwise ~ trial_num0|QUIC,  
        at = list(QUIC = c(-1, 1),
                  trial_num0 = c(0, 14, 29)))
```

##### Affective reward
```{r eval=FALSE}
random_structure = "(1 + trial_num0| id)"
predictors = c("QUIC*trial_num0", covariates, random_structure)
mod1_MIA <- model_fun("go", predictors, df_gng_glmm_MIA)
saveRDS(mod1_MIA, file.path(gng_dir, "models/mod1_MIA.rds"))
```

```{r}
mod1_MIA <- readRDS(file.path(gng_dir, "models/mod1_MIA.rds"))
summary(mod1_MIA)
tab_model(mod1_MIA)

(plot_model(mod1_MIA, type="emm",
            terms=c("trial_num0 [all]", "QUIC [-1, 1]"), 
            title = "MIA_go_QUIC*trial_num0",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_QUIC*trial_num0.png"), width = 15, height = 10, units = "cm")
```

```{r eval=FALSE}
# multiple comparison for interaction
# contrast 1
emmeans(mod1_MIA, pairwise ~ QUIC|trial_num0,  
        at = list(QUIC = c(-1, 1),
                  trial_num0 = c(0, 14, 29)))
# contrast 2
emmeans(mod1_MIA, pairwise ~ trial_num0|QUIC,  
        at = list(QUIC = c(-1, 1),
                  trial_num0 = c(0, 14, 29)))
```

#### Mod2: Whether the learning of **go and nogo cues** vary with unpredictability?

##### Monetary reward

```{r}
# reference level: "no go"
random_structure = "(1 + go_str + trial3| id)"
predictors = c("go_str*QUIC*trial3", covariates, random_structure)
mod2 <- model_fun("go", predictors, df_gng_glmm_LIA)
saveRDS(mod2, file.path(gng_dir, "models/mod2.rds"))

# reference level: "go"
random_structure = "(1 + go_strR + trial3| id)"
predictors = c("go_strR*QUIC*trial3", covariates, random_structure)
mod2_ref_go <- model_fun("go", predictors, df_gng_glmm_LIA)
saveRDS(mod2_ref_go, file.path(gng_dir, "models/mod2_ref_go.rds"))
```

```{r}
mod2 <- readRDS(file.path(gng_dir, "models/mod2.rds"))
summary(mod2)
# sjPlot::tab_model(mod2)

mod2_ref_go <- readRDS(file.path(gng_dir, "models/mod2_ref_go.rds"))
summary(mod2_ref_go)
# sjPlot::tab_model(mod2_ref_go)

(plot_model(mod2, type="emm",
            terms=c("QUIC [all]", "go_str", "trial3 [3, 15, 30]"), 
            title = "MIA_go_go_str*QUIC*trial3",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_go_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

```{r}
# multiple comparison for interaction
# contrast 1
emmeans(mod2, pairwise ~ QUIC|trial3, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2, pairwise ~ trial3|QUIC, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2, pairwise ~ trial3|go_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 4
emmeans(mod2, pairwise ~ go_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

##### Affective reward

```{r}
# reference level: "no go"
random_structure = "(1 + go_str + trial3| id)"
predictors = c("go_str*QUIC*trial3", covariates, random_structure)
mod2 <- model_fun("go", predictors, df_gng_glmm_MIA)
saveRDS(mod2, file.path(gng_dir, "models/mod2.rds"))

# reference level: "go"
random_structure = "(1 + go_strR + trial3| id)"
predictors = c("go_strR*QUIC*trial3", covariates, random_structure)
mod2_ref_go <- model_fun("go", predictors, df_gng_glmm_MIA)
saveRDS(mod2_ref_go, file.path(gng_dir, "models/mod2_ref_go.rds"))
```

```{r}
mod2 <- readRDS(file.path(gng_dir, "models/mod2.rds"))
summary(mod2)
# sjPlot::tab_model(mod2)

mod2_ref_go <- readRDS(file.path(gng_dir, "models/mod2_ref_go.rds"))
summary(mod2_ref_go)
# sjPlot::tab_model(mod2_ref_go)

(plot_model(mod2, type="emm",
            terms=c("QUIC [all]", "go_str", "trial3 [3, 15, 30]"), 
            title = "MIA_go_go_str*QUIC*trial3",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_go_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

```{r}
# multiple comparison for interaction
# contrast 1
emmeans(mod2, pairwise ~ QUIC|trial3, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2, pairwise ~ trial3|QUIC, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2, pairwise ~ trial3|go_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 4
emmeans(mod2, pairwise ~ go_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

#### Mod2_val: Whether the learning of **Pos and Neg feedback** vary with unpredictability?

##### Monetary reward

```{r}
# reference level: "negative"
random_structure = "(1 + val_str + trial3| id)"
predictors = c("val_str*QUIC*trial3", covariates, random_structure)
mod2_val <- model_fun("go", predictors, df_gng_glmm_LIA)
saveRDS(mod2_val, file.path(gng_dir, "models/mod2_val.rds"))

# reference level: "positive"
random_structure = "(1 + val_strR + trial3| id)"
predictors = c("val_strR*QUIC*trial3", covariates, random_structure)
mod2_val_ref_positive <- model_fun("go", predictors, df_gng_glmm_LIA)
saveRDS(mod2_val_ref_positive, file.path(gng_dir, "models/mod2_val_ref_positive.rds"))
```

```{r}
mod2_val <- readRDS(file.path(gng_dir, "models/mod2_val.rds"))
summary(mod2_val)
# sjPlot::tab_model(mod2_val)

mod2_val_ref_positive <- readRDS(file.path(gng_dir, "models/mod2_val_ref_positive.rds"))
summary(mod2_val_ref_positive)
# sjPlot::tab_model(mod2_val_ref_positive)

(plot_model(mod2_val, type="emm",
            terms=c("QUIC",  "val_str", "trial3 [3, 15, 30]"),
            title = "MIA_go_val_str*QUIC*trial_num_3int",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir,"MIA_go_val_str*QUIC*trial_num_3int.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_val, type="emm",
            terms=c("QUIC [all]", "val_str"), # adding [all] makes the plot end right at the maximum value of x-axis
            title = "MIA_go_val_str*QUIC*trial_num_2int",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_val_str*QUIC*trial_num_2int.png"), width = 15, height = 10, units = "cm")
```

```{r}
# multiple comparison for interaction
# contrast 1
emmeans(mod2_val, pairwise ~ QUIC|trial3, by = "val_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_val, pairwise ~ val_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_val, pairwise ~ trial3|val_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

##### Affective reward

```{r}
# reference level: "negative"
random_structure = "(1 + val_str + trial3| id)"
predictors = c("val_str*QUIC*trial3", covariates, random_structure)
mod2_val <- model_fun("go", predictors, df_gng_glmm_MIA)
saveRDS(mod2_val, file.path(gng_dir, "models/mod2_val.rds"))

# reference level: "positive"
random_structure = "(1 + val_strR + trial3| id)"
predictors = c("val_strR*QUIC*trial3", covariates, random_structure)
mod2_val_ref_positive <- model_fun("go", predictors, df_gng_glmm_MIA)
saveRDS(mod2_val_ref_positive, file.path(gng_dir, "models/mod2_val_ref_positive.rds"))
```

```{r}
mod2_val <- readRDS(file.path(gng_dir, "models/mod2_val.rds"))
summary(mod2_val)
# sjPlot::tab_model(mod2_val)

mod2_val_ref_positive <- readRDS(file.path(gng_dir, "models/mod2_val_ref_positive.rds"))
summary(mod2_val_ref_positive)
# sjPlot::tab_model(mod2_val_ref_positive)

(plot_model(mod2_val, type="emm",
            terms=c("QUIC",  "val_str", "trial3 [3, 15, 30]"),
            title = "MIA_go_val_str*QUIC*trial_num_3int",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir,"MIA_go_val_str*QUIC*trial_num_3int.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_val, type="emm",
            terms=c("QUIC [all]", "val_str"), # adding [all] makes the plot end right at the maximum value of x-axis
            title = "MIA_go_val_str*QUIC*trial_num_2int",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_val_str*QUIC*trial_num_2int.png"), width = 15, height = 10, units = "cm")
```

```{r}
# multiple comparison for interaction
# contrast 1
emmeans(mod2_val, pairwise ~ QUIC|trial3, by = "val_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_val, pairwise ~ val_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_val, pairwise ~ trial3|val_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

#### Results by cue types

##### Go for positive trials

###### Monetary reward
```{r}
data = subset(df_gng_glmm_LIA, cue == 0)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_0 <- model_fun("go", predictors, data)
saveRDS(mod2_0, file.path(gng_dir, "models/mod2_0.rds"))
```

```{r}
mod2_0 <- readRDS(file.path(gng_dir, "models/mod2_0.rds"))
summary(mod2_0)
# sjPlot::tab_model(mod2_0)

(plot_model(mod2_0, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue0_QUIC*trial3",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue0_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward
```{r}
data = subset(df_gng_glmm_MIA, cue == 0)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_0 <- model_fun("go", predictors, data)
saveRDS(mod2_0, file.path(gng_dir, "models/mod2_0.rds"))
```

```{r}
mod2_0 <- readRDS(file.path(gng_dir, "models/mod2_0.rds"))
summary(mod2_0)
# sjPlot::tab_model(mod2_0)

(plot_model(mod2_0, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue0_QUIC*trial3",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue0_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### NoGo for positive trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 1)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_1 <- model_fun("go", predictors, data)
saveRDS(mod2_1, file.path(gng_dir, "models/mod2_1.rds"))
```

```{r}
mod2_1 <- readRDS(file.path(gng_dir, "models/mod2_1.rds"))
summary(mod2_1)
# sjPlot::tab_model(mod2_1)

(plot_model(mod2_1, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue1_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue1_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 1)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_1 <- model_fun("go", predictors, data)
saveRDS(mod2_1, file.path(gng_dir, "models/mod2_1.rds"))
```

```{r}
mod2_1 <- readRDS(file.path(gng_dir, "models/mod2_1.rds"))
summary(mod2_1)
# sjPlot::tab_model(mod2_1)

(plot_model(mod2_1, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue1_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue1_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### Go to avoid negative trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_LIA, cue == 2)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_2 <- model_fun("go", predictors, data)
saveRDS(mod2_2, file.path(gng_dir, "models/mod2_2.rds"))
```

```{r}
mod2_2 <- readRDS(file.path(gng_dir, "models/mod2_2.rds"))
summary(mod2_2)
# sjPlot::tab_model(mod2_2)

(plot_model(mod2_2, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue2_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue2_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 2)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_2 <- model_fun("go", predictors, data)
saveRDS(mod2_2, file.path(gng_dir, "models/mod2_2.rds"))
```

```{r}
mod2_2 <- readRDS(file.path(gng_dir, "models/mod2_2.rds"))
summary(mod2_2)
# sjPlot::tab_model(mod2_2)

(plot_model(mod2_2, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue2_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue2_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### NoGo to avoid negative trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_LIA, cue == 3)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_3 <- model_fun("go", predictors, data)
saveRDS(mod2_3, file.path(gng_dir, "models/mod2_3.rds"))
```

```{r}
mod2_3 <- readRDS(file.path(gng_dir, "models/mod2_3.rds"))
summary(mod2_3)
# sjPlot::tab_model(mod2_3)

(plot_model(mod2_3, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue3_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue3_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 3)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_3 <- model_fun("go", predictors, data)
saveRDS(mod2_3, file.path(gng_dir, "models/mod2_3.rds"))
```

```{r}
mod2_3 <- readRDS(file.path(gng_dir, "models/mod2_3.rds"))
summary(mod2_3)
# sjPlot::tab_model(mod2_3)

(plot_model(mod2_3, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue3_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue3_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```



### DV: Correct

##### does unpredictability bias children's accuracy?

The model where trial_num0 is a quadratic term (quadratic learning curve) has a lower AIC (prefer goodness of fit) but larger BIC (prefer simpler models), and has a significant p-value in the chi-square test, suggesting that it provides a better model-fit but at the same time is not parsimonious (might be over fitting the current data). Be cautious about this trade-off.

```{r eval=FALSE}
# trial_num0 as a linear term (linear learning curve)
random_structure = "(1 + trial_num0| id)"
predictors = c("QUIC*trial_num0", covariates, random_structure)
mod1_correct <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod1_correct, file.path(gng_dir, "models/mod1_correct.rds"))

# trial_num0 as a quadratic term (quadratic learning curve)
random_structure = "(1 + poly(trial_num0,2,raw=FALSE)| id)"
predictors = c("QUIC*poly(trial_num0,2,raw=FALSE)", covariates, random_structure)
mod1_correct_poly <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod1_correct_poly, file.path(gng_dir, "models/mod1_correct_poly.rds"))
```

```{r eval=FALSE}
mod1_correct <- readRDS(file.path(gng_dir, "models/mod1_correct.rds"))
summary(mod1_correct)
# sjPlot::tab_model(mod1_correct)

mod1_correct_poly <- readRDS(file.path(gng_dir, "models/mod1_correct_poly.rds"))
summary(mod1_correct_poly)
# sjPlot::tab_model(mod1_correct_poly)

anova(mod1_correct, mod1_correct_poly)

(plot_model(mod1_correct, type="emm",
            terms=c("trial_num0 [all]"), 
            title = "MIA_correct_QUIC*trial_num0",
            axis.title = c("Trial Number", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_correct_QUIC*trial_num0.png"), width = 15, height = 10, units = "cm")

(plot_model(mod1_correct_poly, type="emm",
            terms=c("trial_num0 [all]"), 
            title = "MIA_correct_QUIC*trial_num0^2",
            axis.title = c("Trial Number", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_correct_poly_QUIC*trial_num0^2.png"), width = 15, height = 10, units = "cm")
```

#### whether the accuracy for **go and nogo cues** vary with unpredictability?

The model where trial3 is a quadratic term (quadratic learning curve) has a lower AIC (prefer goodness of fit) but larger BIC (prefer simpler models), and has a significant p-value in the chi-square test, suggesting that it provides a better model-fit but at the same time is not parsimonious (might be over fitting the current data). Be cautious about this trade-off.

```{r eval=FALSE}
random_structure = "(1 + go_str + trial3| id)"
predictors = c("go_str*QUIC*trial3", covariates, random_structure)
mod2_correct <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod2_correct, file.path(gng_dir, "models/mod2_correct.rds"))

# trial3 as a quadratic term
random_structure = "(1 + go_str + poly(trial3,2,raw=FALSE)| id)"
predictors = c("go_str*QUIC*poly(trial3,2,raw=FALSE)", covariates, random_structure)
mod2_correct_poly <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod2_correct_poly, file.path(gng_dir, "models/mod2_correct_poly.rds"))
```

```{r}
mod2_correct <- readRDS(file.path(gng_dir, "models/mod2_correct.rds"))
summary(mod2_correct)
# sjPlot::tab_model(mod2_correct)

mod2_correct_poly <- readRDS(file.path(gng_dir, "models/mod2_correct_poly.rds"))
summary(mod2_correct_poly)
# sjPlot::tab_model(mod2_correct_poly)

anova(mod2_correct, mod2_correct_poly)

# (plot_model(mod2_correct, type="emm",
#             terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"), 
#             title = "MIA_correct_go_str*QUIC*trial3",
#             # axis.title = c("Unpredictability (Standardized)", "% Go"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# ggsave(filename = file.path(plots_dir,"MIA_correct_go_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_correct_poly, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = "MIA_correct_poly_go_str*QUIC*trial3",
            # axis.title = c("Trial Number", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_correct_poly_QUIC*go_str*trial3.png"), width = 15, height = 10, units = "cm")

# (plot_model(mod2_correct_poly, type="emm",
#             # terms=c("trial3", "go_str", "QUIC"),
#             terms=c("trial3", "QUIC"),
#             title = "MIA_correct_poly_str*QUIC*trial3",
#             # axis.title = c("Trial Number", "Accuracy"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# # ggsave(filename = file.path(plots_dir,"MIA_correct_poly_go_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_correct_poly, type="emm",
            terms=c("trial3", "go_str", "QUIC [-1, 0, 1]"),
            # terms=c("trial3", "QUIC"), 
            title = "MIA_correct_poly_trial3*go_str*QUIC",
            # axis.title = c("Trial Number", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_correct_poly_trial3*go_str*QUIC.png"), width = 15, height = 10, units = "cm")
```

#### whether the accuracy for **Pos and Neg feedback** vary with unpredictability?

The model where trial3 is a quadratic term (quadratic learning curve) has a larger AIC (prefer goodness of fit) and larger BIC (prefer simpler models), and p-value in the chi-square test is not significant, suggesting that the simpler model is preferable.

```{r eval=FALSE}
random_structure = "(1 + val_str + trial3| id)" # model with "(1 + val_str + trial3| id)" can't converge
predictors = c("val_str*QUIC*trial3", covariates, random_structure)
mod2_val_correct <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod2_val_correct, file.path(gng_dir, "models/mod2_val_correct.rds"))

# trial3 as a quadratic term
random_structure = "(1 + val_str + poly(trial3,2,raw=FALSE) + trial3| id)"
predictors = c("val_str*QUIC*poly(trial3,2,raw=FALSE)", covariates, random_structure)
mod2_val_correct_poly <- model_fun("correct", predictors, df_gng_glmm)
saveRDS(mod2_val_correct_poly, file.path(gng_dir, "models/mod2_val_correct_poly.rds"))
```

There is no effect of unpredictability in how children learn to respond to cues with potential positive and negative feedback (see coefficient for "QUIC", "val_strpositive:QUIC", "QUIC:trial3", and "val_strpositive:QUIC:trial3").

```{r}
mod2_val_correct <- readRDS(file.path(gng_dir, "models/mod2_val_correct.rds"))
summary(mod2_val_correct)
# sjPlot::tab_model(mod2_val_correct)

mod2_val_correct_poly <- readRDS(file.path(gng_dir, "models/mod2_val_correct_poly.rds"))
summary(mod2_val_correct_poly)
# sjPlot::tab_model(mod2_val_correct_poly)

anova(mod2_val_correct, mod2_val_correct_poly)

(plot_model(mod2_val_correct, type="emm",
            terms=c("QUIC", "val_str", "trial3 [0, 15, 30]"),
            title = "MIA_correct_val_str*QUIC*trial3",
            # axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir,"MIA_correct_val_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")

# (plot_model(mod2_val_correct_poly, type="emm",
#             terms=c("QUIC", "val_str", "trial3 [0, 15, 30]"),
#             title = "MIA_correct_poly_val_str*QUIC*trial3",
#             # axis.title = c("Trial Number", "Accuracy"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# ggsave(filename = file.path(plots_dir,"MIA_correct_poly_val_str*QUIC*trial3.png"), width = 15, height = 10, units = "cm")
# 
# (plot_model(mod2_val_correct_poly, type="emm",
#             terms=c("trial3", "val_str", "QUIC [-1, 0, 1]"),
#             # terms=c("trial3", "QUIC"), 
#             title = "MIA_correct_poly_trial3*val_str*QUIC",
#             # axis.title = c("Trial Number", "Accuracy"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# ggsave(filename = file.path(plots_dir,"MIA_correct_poly_trial3*val_str*QUIC.png"), width = 15, height = 10, units = "cm")
```

### DV: Learners vs Non-learners

```{r eval=FALSE}
# classify Learners and Non-learners according to the second half of the task
df_learner <- df_gng_glmm %>% filter(trial_num > 15) %>% 
  group_by(id) %>% summarise(accuracy = mean(correct)) %>% 
  full_join(., df_gng_glmm) %>% 
  group_by(id) %>% slice(1) %>% 
  mutate(learner_status = if_else(accuracy > .50, "Learner", "Non-learner") %>% as.factor) # according to de Berker paper

# Finding the top and bottom 20% cutoffs for quic
(top_cutoff <- quantile(df_learner$QUIC, probs = 0.8))
(bottom_cutoff <- quantile(df_learner$QUIC, probs = 0.2))

# Identifying top and bottom 20% kids for quic
df_learner <- df_learner %>% mutate(quic_status = case_when(QUIC >= top_cutoff ~ "Top20%",
                                                            QUIC <= bottom_cutoff ~ "Bottom20%",
                                                            .default = NA))
```

#### Regression

```{r eval=FALSE}
mod_learner <- glm(learner_status ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_learner, family = "binomial")
summary(mod_learner)
plot_model(mod_learner)
```

#### Chi square test

```{r eval=FALSE}
# analysis and intrepretation following this source: http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r
# Chi square test results
chisq <- chisq.test(with(df_learner, table(quic_status,learner_status)))
chisq
# Observed counts
chisq$observed
# Expected counts
round(chisq$expected,2)

# Contribution in percentage (%)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(contrib, 3)
# Visualize the contribution ()
corrplot(contrib, is.cor = FALSE)
```

### DV: Pavlovian bias

```{r eval=FALSE}
df_pav <- df_gng_glmm %>% group_by(id) %>% slice(1)

mod_pav_reward <- lm(pav_reward_bias ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_pav)
mod_pav_punish <- lm(pav_punish_bias ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_pav)
summary(mod_pav_reward)
summary(mod_pav_punish)
```

# Understanding check

```{r eval=FALSE}
# prep data
df_check <- df_learner %>% mutate(accuracy_diff = accuracy_check - accuracy)

# Pearson correlation between task accuracy in the second half and understanding check accuracy
(check_cor1 <- cor.test(df_check$accuracy, df_check$accuracy_check, method = "pearson"))
(check_cor2 <- cor.test(df_check$QUIC, df_check$accuracy, method = "pearson"))
(check_cor3 <- cor.test(df_check$QUIC, df_check$accuracy_check, method = "pearson"))
(check_cor4 <- cor.test(df_check$QUIC, df_check$accuracy_diff, method = "pearson"))

# visualize the correlation
library("ggpubr")
ggscatter(df_check, x = "accuracy", y = "accuracy_check", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Task accuracy", ylab = "Understanding check accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Task accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy_check", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Understanding check accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy_diff", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Difference between learning and use")

# which individual difference might predict the difference between learning and use?
summary(lm(accuracy_diff ~ QUIC + Digit_span + Family_income + Perceived_stress + conflict_total, data = df_check))
```

## In the first half of the task

##### whether the learning of **go and nogo cues** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num <= 15)
random_structure = "(1 + go_str + trial_num| id)"

predictors = c("go_str*QUIC*trial_num", covariates, random_structure)
mod2 <- model_fun("go", predictors, data)
summary(mod2)
# sjPlot::tab_model(mod2)
```

```{r eval=FALSE}
(plot_model(mod2, type="eff",
            terms=c("QUIC", "go_str", "trial_num [5, 10, 15]"), 
            title = "MIA: Learning of Go/NoGo cues in 1st half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### positive trials

```{r eval=FALSE}
data <- df_gng_glmm %>% filter(win_maintain == 1) %>% filter(trial_num <= 15)
print("Glancing each id: ")
sort(table(data$id))

mod2_pos <- model_fun("go", predictors, data)
summary(mod2_pos)
# sjPlot::tab_model(mod2)
```

```{r eval=FALSE}
(plot_model(mod2_pos, type="eff",
            terms=c("trial_num", "go_str"), 
            title = "MIA: Learning of Go/NoGo cues in positive trials during 1st half",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_positive_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### negative trials

```{r eval=FALSE}
data <- df_gng_glmm %>% filter(win_maintain == 0) %>% filter(trial_num <= 15)
print("Glancing each id: ")
sort(table(data$id))

mod2_neg <- model_fun("go", predictors, data)
summary(mod2_neg)
```

```{r eval=FALSE}
(plot_model(mod2_neg, type="eff",
            terms=c("trial_num", "go_str"), 
            title = "MIA: Learning of Go/NoGo cues in negative trials during 1st half",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_negative_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### whether the learning of **Pos and Neg feedback** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num <= 15)
random_structure = "(1 + val_str + trial_num| id)"
predictors = c("val_str*QUIC*trial_num", covariates, random_structure)
mod2_val <- model_fun("go", predictors, data)
summary(mod2_val)
# sjPlot::tab_model(mod2_val)
```

```{r eval=FALSE}
# inf_mod2 <- influence(mod2_val, "id", maxfun=100)
# infIndexPlot(inf_mod2)
# plot((dfbetas(inf_mod2)[, "val_strpositive:QUIC:trial_num"]))
# 
# mod2_val.1 <- update(mod2_val, subset = id != c('2028', '2018')) # check deleting ids with high cook's distance
# inf_mod2.1 <- influence(mod2_val.1, "id", maxfun=100)
# infIndexPlot(inf_mod2.1)
# compareCoefs(mod2_val, mod2_val.1)
# 
# dfbeta(inf_mod2)
# dfbetas(inf_mod2)
```

```{r eval=FALSE}
# (plot_model(mod2_val, type="eff",
#             terms=c("QUIC", "val_str", "trial_num [5, 10, 15]"), 
#             title = "MIA: Learning of Pos/Neg cues in 1st half",
#             axis.title = c("Unpredictability (Standardized)", "% Go"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# # + ylim(0.3,1)
# ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_val, type="eff",
            terms=c("QUIC", "val_str"), 
            title = "MIA: Learning of Pos/Neg cues in 1st half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")
```

## In the second half of the task

##### whether the learning of **go and nogo cues** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num > 15)
random_structure = "(1 + go_str + trial_num| id)"
predictors = c("go_str*QUIC*trial_num", covariates, random_structure)
mod3 <- model_fun("go", predictors, data)
summary(mod3)
# sjPlot::tab_model(mod3)
```

##### whether the learning of **Pos and Neg feedback** vary with unpredictability

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num > 15)
random_structure = "(1 + val_str + trial_num| id)"
predictors = c("val_str*QUIC*trial_num", covariates, random_structure)
mod3_val <- model_fun("go", predictors, data)
summary(mod3_val)
# sjPlot::tab_model(mod3_val)
```

```{r eval=FALSE}
# (plot_model(mod2_val, type="eff",
#             terms=c("QUIC", "val_str", "trial_num [5, 10, 15]"), 
#             title = "MIA: Learning of Pos/Neg cues in 1st half",
#             axis.title = c("Unpredictability (Standardized)", "% Go"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# # + ylim(0.3,1)
# ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")

(plot_model(mod3_val, type="eff",
            terms=c("QUIC", "val_str", "trial_num [20, 25, 30]"), 
            title = "MIA: Learning of Pos/Neg cues in 2nd half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_valence_learning_2nd_half.png"), width = 15, height = 10, units = "cm")
```

# Exploratory

### Cluster analyses

##### prep data

```{r eval=FALSE}
df_cluster <- gng_wide %>% left_join(., df_covar) %>% mutate_each_(funs(factor(.)),c("cluster_k2","cluster_k3","cluster_k4"))

table(df_cluster$cluster_k2)
table(df_cluster$cluster_k3)
table(df_cluster$cluster_k4)
##### things to consider: potential problem of uneven cluster?

# distribution of each variable across the 3 groups -- numeric
with(df_cluster, do.call(rbind, 
                         tapply(QUIC, cluster_k3, 
                                function(x) c(M = mean(x, na.rm = TRUE), SD = sd(x, na.rm = TRUE)))))

# distribution of each variable across the 3 groups -- histogram
ggplot(df_cluster, aes(x = QUIC)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .) # group 2 seems to have the most QUIC score
ggplot(df_cluster, aes(x = Perceived_stress)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = Digit_span)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = conflict_total)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = Family_income)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)

############ experimenting plotting codes ############
hist_fun <- function(var, cluster) {
  p <- ggplot(df_cluster, aes(x = get(var))) +
    geom_histogram(position="identity") +
    facet_grid(get(cluster) ~ .)
  return(p)
}

vars <- c("QUIC","Perceived_stress","Digit_span","Family_income","conflict_total")
clusters <- c("cluster_k2","cluster_k3","cluster_k4")
list <- mapply(hist_fun, vars, clusters) # look for how to show the plots as the codes below
```

##### multinomial regression

This analysis uses unpredictability and other covariates (continuous variables) to predict the chance of being in each clusters (nominal variable). Results show that none of the predictors were significant. \*refer to this source: <https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/>

```{r eval=FALSE}
df_cluster$cluster_k2_new <- relevel(df_cluster$cluster_k2, ref = "1")
df_cluster$cluster_k3_new <- relevel(df_cluster$cluster_k3, ref = "1")
df_cluster$cluster_k4_new <- relevel(df_cluster$cluster_k4, ref = "2")

fit2 <- multinom(cluster_k2_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit3 <- multinom(cluster_k3_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit4 <- multinom(cluster_k4_new ~ QUIC + Digit_span + Family_income, data = df_cluster)

tbl_regression(fit2, exp = TRUE)
tbl_regression(fit3, exp = TRUE)
tbl_regression(fit4, exp = TRUE)
```

```{r eval=FALSE}
df_cluster$cluster_k2_new <- relevel(df_cluster$cluster_k2, ref = "1")
df_cluster$cluster_k3_new <- relevel(df_cluster$cluster_k3, ref = "2")
df_cluster$cluster_k4_new <- relevel(df_cluster$cluster_k4, ref = "4")

fit2 <- multinom(cluster_k2_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit3 <- multinom(cluster_k3_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit4 <- multinom(cluster_k4_new ~ QUIC + Digit_span + Family_income, data = df_cluster)

tbl_regression(fit2, exp = TRUE)
tbl_regression(fit3, exp = TRUE)
tbl_regression(fit4, exp = TRUE)
```