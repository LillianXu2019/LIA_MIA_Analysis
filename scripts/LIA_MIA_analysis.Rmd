---
title: "LIA_MIA_analysis"
author: "Yuyan Xu"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE)
```

# Source functions

```{r results='hide'}
source('Source/Setup.R')
source('Source/Functions.R')
```

```{r}
source('Source/ReadData.R')
```

*** 

# Descriptives 

## inspect missingness

### predictors

```{r}
list_predictors <- c("QUIC", "Digit_span", "Family_income")
```

### missing patterns
Note: the missing data graph tells us the observations that have missing values for each variable (single dots) and the observations that have missing values in multiple variables together (linked dots).  
Source: https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html

#### LIA data
```{r}
df_pred_LIA3 <- df_predictors %>% 
  filter(id %in% subset(gng_long, version == "third")$id) %>% 
  select(list_predictors)

print("Missing data for each variable in LIA - third version:")
df_pred_LIA3 %>% summarize_all(~ sum(is.na(.))) %>% glimpse()
df_pred_LIA3 %>% gg_miss_upset(.)

df_pred_LIA3 <- df_pred_LIA3 %>% na.omit()
paste("Sample size for LIA - third version predictors: ", nrow(df_pred_LIA3))
```

#### MIA data
```{r}
df_pred_MIA <- df_predictors %>% 
  filter(id %in% subset(gng_long, version == "MIA")$id) %>% 
  select(list_predictors)

print("Missing data for each variable in MIA:")
df_pred_MIA %>% summarize_all(~ sum(is.na(.))) %>% glimpse()
df_pred_MIA %>% gg_miss_upset(.)

df_pred_MIA <- df_pred_MIA %>% na.omit()
paste("Sample size for MIA predictors: ", nrow(df_pred_MIA))
```

## predictor summary
```{r}
print("LIA summary:")
df_pred_LIA3 %>% st(.)
print("MIA summary:")
df_pred_MIA %>% st(.)

# t-test
ttest_LIA <- df_pred_LIA3 %>% mutate(study = "LIA")
ttest_MIA <- df_pred_MIA %>% mutate(study = "MIA")
ttest <- rbind(ttest_LIA,ttest_MIA)

a <- nice_t_test(data = ttest, response = "QUIC", group = "study", alternative = "two.sided", var.equal = TRUE) 
b <- nice_t_test(data = ttest, response = "Digit_span", group = "study", alternative = "two.sided", var.equal = TRUE) 
c <- nice_t_test(data = ttest, response = "Family_income", group = "study", alternative = "two.sided", var.equal = TRUE) 

bind_rows(a, b, c)
rm(a, b, c, ttest_LIA, ttest_MIA, ttest)
```

## predictor correlations
The correlation between family income and QUIC is very different in LIA and MIA samples.
```{r}
print("LIA correltaion:")
ggpairs(df_pred_LIA3, title="") + theme_bw()
print("MIA correltaion:")
ggpairs(df_pred_MIA, title="") + theme_bw()
```

## learning curve plot
LIA 
image: ![](../plots/gonogo_task/third_cues.png)  

MIA 
image: ![](../plots/gonogo_task/MIA_cues.png)  

*** 

# GNG TASK

## prep data

cue (index.html line 263-275):\
0 = go to win\
1 = no go to win\
2 = go to maintain\
3 = no go to maintain

```{r}
# select variables to standardize
vars <- c('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress', 'Parent_child_conflict')

##################### long data #####################
df_gng_glmm <- left_join(gng_long, df_predictors, by = 'id') %>% 
  mutate(go_str = factor(go_nogo, levels=0:1, labels=c("no go", "go")),
         go_strR = relevel(go_str, ref = "go"), # relevel the reference level to "go" 
         val_str = factor(win_maintain, levels=0:1, labels=c("negative", "positive")),
         val_strR = relevel(val_str, ref = "positive"), # relevel the reference level to "positive" 
         nonswitch = factor(nonswitch, levels=0:1, labels=c("switch", "no switch")),
         phase = if_else(trial_num < 16, "first half", "second half") %>% as.factor,
         trial_num0 = trial_num - 1) %>% 
  filter_at(c('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress'), all_vars(!is.na(.))) %>%
  mutate_at(vars, ~(scale(.) %>% as.vector)) 

df_gng_glmm_LIA <- df_gng_glmm %>% filter(version == "third")
df_gng_glmm_MIA <- df_gng_glmm %>% filter(version == "MIA")
# paste("GNG task total N: ", n_distinct(gng_long$id))
paste0("After removing incomplete data in predicting variables ('QUIC', 'Digit_span', 'Family_income', 'Perceived_stress'): ")
paste0("-- Monetary Reward (LIA) sample size - third version: ", n_distinct(df_gng_glmm_LIA$id))
paste0("-- Affective Reward (MIA) sample size: ", n_distinct(df_gng_glmm_MIA$id))
```

## covariates

```{r include=FALSE}
covariates = "Digit_span + Family_income + Perceived_stress"
paste0("Covariates: ", covariates)
```

### functions

```{r}
run_models <- function(study, covariates, model_setup) {
  if (study == "LIA") {data = df_gng_glmm_LIA} else {data = df_gng_glmm_MIA}
  for (i in 1:nrow(model_setup)) {
    mod_name <- paste0(model_setup[i, "mod_name"], study)
    print(mod_name)
    response <- model_setup[i, "response"]
    key_var <- model_setup[i, "key_var"]
    random_structure <- model_setup[i, "random_structure"]
    
    predictors = c(key_var, covariates, random_structure)
    mod <- model_fun(response, predictors, data)
    
    assign(mod_name, mod, envir = .GlobalEnv)
    saveRDS(get(mod_name), file.path(gng_dir, paste0("models/", mod_name, ".rds")))
  }
}

tidy_mod_fun <- function(model_list) {
  for (i in (1:length(model_list))) {
    name <- names(model_list)[[i]]
    mod <- model_list[[i]]
    
    if (class(mod) == "glmerMod") {
      table <- mod %>% tidy(conf.int = TRUE, exp = TRUE) 
    } else {
      table <- mod %>% tidy(conf.int = TRUE)
    }
    
    table <- table %>% mutate(name = name)
    summary <- bind_rows(summary, table)
  }
  return(summary)
}
```

### model specifications

**DV: Go**  
*Mod1*: Does unpredictability bias children's Go/NoGo response?  
*Mod2*: Whether the learning of **go and nogo cues** vary with unpredictability? 
*Mod2_val*: Whether the learning of **positive and negative valence feedback** vary with unpredictability?  

**DV: Correct**  
*Mod1_correct*: does unpredictability bias children's accuracy?  
*Mod2_correct*: whether the accuracy for **go and nogo cues** vary with unpredictability? 
*Mod2_val_correct*: whether the accuracy for **positive and negative valence feedback** vary with unpredictability? 

In addition, for accuracy models, we compared models with and without a polynomial term of *trial3* to test the possibility of non-linear learning curve:  
*Mod1_correct_poly*
*Mod2_correct_poly*
*Mod2_val_correct_poly*
```{r}
model_setup <- read_csv("mod_specs.csv")
```

### run models

```{r eval=FALSE}
run_models("LIA", covariates, model_setup)
run_models("MIA", covariates, model_setup)
```

### read in models

```{r}
# Make a vector of all your file paths
file_paths <- list.files(path = file.path(gng_dir, "models"), pattern = "\\.rds", full.names = TRUE)

# Make a vector of file names
file_names <-  gsub(pattern = "\\.rds$", replacement = "", x = basename(file_paths))

# Read all your data into a list
data_list <- lapply(file_paths, readRDS)

# Assign file names to list elements
names(data_list) <- file_names      
```

### summarize models

```{r}
summary <- tibble()
summary <- tidy_mod_fun(data_list) %>% 
  filter(!is.na(std.error)) %>% 
  select(-c(effect, group)) %>% 
  filter(str_detect(term, "QUIC"))
write_csv(summary, file.path(gng_dir, "model_summary.csv"))
```

### compare models

```{r eval=FALSE}
mod1_correctLIA <- readRDS(file.path(gng_dir, "models/mod1_correctLIA.rds"))
mod1_correct_polyLIA <- readRDS(file.path(gng_dir, "models/mod1_correct_polyLIA.rds"))
mod2_val_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctLIA.rds"))
mod2_val_correct_polyLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correct_polyLIA.rds"))

mod1_correctMIA <- readRDS(file.path(gng_dir, "models/mod1_correctMIA.rds"))
mod1_correct_polyMIA <- readRDS(file.path(gng_dir, "models/mod1_correct_polyMIA.rds"))
mod2_val_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctMIA.rds"))
mod2_val_correct_polyMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correct_polyMIA.rds"))
```

Across both LIA and MIA studies, accuracy models **without** the polynomial terms have lower AIC and BIC, indicating a better model fit.  

```{r eval=FALSE}
anova(mod1_correctLIA, mod1_correct_polyLIA)
anova(mod2_val_correctLIA, mod2_val_correct_polyLIA)

anova(mod1_correctMIA, mod1_correct_polyMIA)
anova(mod2_val_correctMIA, mod2_val_correct_polyMIA)
```

### plot models

```{r}
mod2_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_correctLIA.rds"))
mod2_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_correctMIA.rds"))
mod2_val_correctLIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctLIA.rds"))
mod2_val_correctMIA <- readRDS(file.path(gng_dir, "models/mod2_val_correctMIA.rds"))
```

#### whether the accuracy for **go and nogo cues** vary with unpredictability?

##### Monetary reward (LIA)
```{r}
title = paste0("mod2_correctLIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_correctLIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

##### Affective reward (MIA)
```{r}
title = paste0("mod2_correctMIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_correctMIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

#### whether the accuracy for **Pos and Neg feedback** vary with unpredictability?

##### Monetary reward (LIA)
```{r}
title = paste0("mod2_val_correctLIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_val_correctLIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

##### Affective reward (MIA)
```{r}
title = paste0("mod2_val_correctMIA", "_", "QUIC:go_str:trial3")
print(title)
(plot_model(mod2_val_correctMIA, type="emm",
            terms=c("QUIC", "go_str", "trial3 [3, 15, 30]"),
            title = title,
            axis.title = c("Unpredictability (Standardized)", "Accuracy"),
            show.data = FALSE, jitter= NULL, line.size = 1))
ggsave(filename = file.path(plots_dir, paste0(title, ".png")), width = 15, height = 10, units = "cm")
```

### multiple comparison for interaction

#### whether the accuracy for **go and nogo cues** vary with unpredictability?

##### Monetary reward (LIA)

```{r}
# contrast 1
emmeans(mod2_correctLIA, pairwise ~ QUIC|trial3, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_correctLIA, pairwise ~ go_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_correctLIA, pairwise ~ trial3|go_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

##### Affective reward (MIA)

```{r}
# contrast 1
emmeans(mod2_correctMIA, pairwise ~ QUIC|trial3, by = "go_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_correctMIA, pairwise ~ go_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_correctMIA, pairwise ~ trial3|go_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

#### whether the accuracy for **Pos and Neg feedback** vary with unpredictability?

##### Monetary reward (LIA)

```{r}
# contrast 1
emmeans(mod2_val_correctLIA, pairwise ~ QUIC|trial3, by = "val_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_val_correctLIA, pairwise ~ val_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_val_correctLIA, pairwise ~ trial3|val_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

##### Affective reward (MIA)

```{r}
# contrast 1
emmeans(mod2_val_correctMIA, pairwise ~ QUIC|trial3, by = "val_str", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 2
emmeans(mod2_val_correctMIA, pairwise ~ val_str|QUIC, by = "trial3", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
# contrast 3
emmeans(mod2_val_correctMIA, pairwise ~ trial3|val_str, by = "QUIC", 
        at = list(QUIC = c(-1, 1),
                  trial3 = c(3, 15, 30)))
```

#### Results by cue types

##### Go for positive trials

###### Monetary reward
```{r}
data = subset(df_gng_glmm_LIA, cue == 0)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_0 <- model_fun("go", predictors, data)
saveRDS(mod2_0, file.path(gng_dir, "models/mod2_0.rds"))
```

```{r}
mod2_0 <- readRDS(file.path(gng_dir, "models/mod2_0.rds"))
summary(mod2_0)
# sjPlot::tab_model(mod2_0)

(plot_model(mod2_0, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue0_QUIC*trial3",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue0_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward
```{r}
data = subset(df_gng_glmm_MIA, cue == 0)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_0 <- model_fun("go", predictors, data)
saveRDS(mod2_0, file.path(gng_dir, "models/mod2_0.rds"))
```

```{r}
mod2_0 <- readRDS(file.path(gng_dir, "models/mod2_0.rds"))
summary(mod2_0)
# sjPlot::tab_model(mod2_0)

(plot_model(mod2_0, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue0_QUIC*trial3",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue0_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### NoGo for positive trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 1)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_1 <- model_fun("go", predictors, data)
saveRDS(mod2_1, file.path(gng_dir, "models/mod2_1.rds"))
```

```{r}
mod2_1 <- readRDS(file.path(gng_dir, "models/mod2_1.rds"))
summary(mod2_1)
# sjPlot::tab_model(mod2_1)

(plot_model(mod2_1, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue1_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue1_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 1)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_1 <- model_fun("go", predictors, data)
saveRDS(mod2_1, file.path(gng_dir, "models/mod2_1.rds"))
```

```{r}
mod2_1 <- readRDS(file.path(gng_dir, "models/mod2_1.rds"))
summary(mod2_1)
# sjPlot::tab_model(mod2_1)

(plot_model(mod2_1, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue1_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue1_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### Go to avoid negative trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_LIA, cue == 2)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_2 <- model_fun("go", predictors, data)
saveRDS(mod2_2, file.path(gng_dir, "models/mod2_2.rds"))
```

```{r}
mod2_2 <- readRDS(file.path(gng_dir, "models/mod2_2.rds"))
summary(mod2_2)
# sjPlot::tab_model(mod2_2)

(plot_model(mod2_2, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue2_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue2_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 2)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_2 <- model_fun("go", predictors, data)
saveRDS(mod2_2, file.path(gng_dir, "models/mod2_2.rds"))
```

```{r}
mod2_2 <- readRDS(file.path(gng_dir, "models/mod2_2.rds"))
summary(mod2_2)
# sjPlot::tab_model(mod2_2)

(plot_model(mod2_2, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue2_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue2_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

##### NoGo to avoid negative trials

###### Monetary reward

```{r}
data = subset(df_gng_glmm_LIA, cue == 3)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_3 <- model_fun("go", predictors, data)
saveRDS(mod2_3, file.path(gng_dir, "models/mod2_3.rds"))
```

```{r}
mod2_3 <- readRDS(file.path(gng_dir, "models/mod2_3.rds"))
summary(mod2_3)
# sjPlot::tab_model(mod2_3)

(plot_model(mod2_3, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue3_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue3_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

###### Affective reward

```{r}
data = subset(df_gng_glmm_MIA, cue == 3)
random_structure = "(1 + trial3| id)"

predictors = c("QUIC*trial3", covariates, random_structure)
mod2_3 <- model_fun("go", predictors, data)
saveRDS(mod2_3, file.path(gng_dir, "models/mod2_3.rds"))
```

```{r}
mod2_3 <- readRDS(file.path(gng_dir, "models/mod2_3.rds"))
summary(mod2_3)
# sjPlot::tab_model(mod2_3)

(plot_model(mod2_3, type="eff",
            terms=c("trial3", "QUIC [-1, 1]"), 
            title = "MIA_go_cue3_QUIC*trial3.png",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
ggsave(filename = file.path(plots_dir,"MIA_go_cue3_QUIC*trial3.png"), width = 15, height = 10, units = "cm")
```

### DV: Learners vs Non-learners

```{r eval=FALSE}
# classify Learners and Non-learners according to the second half of the task
df_learner <- df_gng_glmm %>% filter(trial_num > 15) %>% 
  group_by(id) %>% summarise(accuracy = mean(correct)) %>% 
  full_join(., df_gng_glmm) %>% 
  group_by(id) %>% slice(1) %>% 
  mutate(learner_status = if_else(accuracy > .50, "Learner", "Non-learner") %>% as.factor) # according to de Berker paper

# Finding the top and bottom 20% cutoffs for quic
(top_cutoff <- quantile(df_learner$QUIC, probs = 0.8))
(bottom_cutoff <- quantile(df_learner$QUIC, probs = 0.2))

# Identifying top and bottom 20% kids for quic
df_learner <- df_learner %>% mutate(quic_status = case_when(QUIC >= top_cutoff ~ "Top20%",
                                                            QUIC <= bottom_cutoff ~ "Bottom20%",
                                                            .default = NA))
```

#### Regression

```{r eval=FALSE}
mod_learner <- glm(learner_status ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_learner, family = "binomial")
summary(mod_learner)
plot_model(mod_learner)
```

#### Chi square test

```{r eval=FALSE}
# analysis and intrepretation following this source: http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r
# Chi square test results
chisq <- chisq.test(with(df_learner, table(quic_status,learner_status)))
chisq
# Observed counts
chisq$observed
# Expected counts
round(chisq$expected,2)

# Contribution in percentage (%)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(contrib, 3)
# Visualize the contribution ()
corrplot(contrib, is.cor = FALSE)
```

### DV: Pavlovian bias

```{r eval=FALSE}
df_pav <- df_gng_glmm %>% group_by(id) %>% slice(1)

mod_pav_reward <- lm(pav_reward_bias ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_pav)
mod_pav_punish <- lm(pav_punish_bias ~ QUIC + Digit_span + Family_income + Perceived_stress, data = df_pav)
summary(mod_pav_reward)
summary(mod_pav_punish)
```

# Understanding check

```{r eval=FALSE}
# prep data
df_check <- df_learner %>% mutate(accuracy_diff = accuracy_check - accuracy)

# Pearson correlation between task accuracy in the second half and understanding check accuracy
(check_cor1 <- cor.test(df_check$accuracy, df_check$accuracy_check, method = "pearson"))
(check_cor2 <- cor.test(df_check$QUIC, df_check$accuracy, method = "pearson"))
(check_cor3 <- cor.test(df_check$QUIC, df_check$accuracy_check, method = "pearson"))
(check_cor4 <- cor.test(df_check$QUIC, df_check$accuracy_diff, method = "pearson"))

# visualize the correlation
library("ggpubr")
ggscatter(df_check, x = "accuracy", y = "accuracy_check", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Task accuracy", ylab = "Understanding check accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Task accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy_check", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Understanding check accuracy")

ggscatter(df_check, x = "QUIC", y = "accuracy_diff", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Unpredictability", ylab = "Difference between learning and use")

# which individual difference might predict the difference between learning and use?
summary(lm(accuracy_diff ~ QUIC + Digit_span + Family_income + Perceived_stress + conflict_total, data = df_check))
```

## In the first half of the task

##### whether the learning of **go and nogo cues** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num <= 15)
random_structure = "(1 + go_str + trial_num| id)"

predictors = c("go_str*QUIC*trial_num", covariates, random_structure)
mod2 <- model_fun("go", predictors, data)
summary(mod2)
# sjPlot::tab_model(mod2)
```

```{r eval=FALSE}
(plot_model(mod2, type="eff",
            terms=c("QUIC", "go_str", "trial_num [5, 10, 15]"), 
            title = "MIA: Learning of Go/NoGo cues in 1st half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### positive trials

```{r eval=FALSE}
data <- df_gng_glmm %>% filter(win_maintain == 1) %>% filter(trial_num <= 15)
print("Glancing each id: ")
sort(table(data$id))

mod2_pos <- model_fun("go", predictors, data)
summary(mod2_pos)
# sjPlot::tab_model(mod2)
```

```{r eval=FALSE}
(plot_model(mod2_pos, type="eff",
            terms=c("trial_num", "go_str"), 
            title = "MIA: Learning of Go/NoGo cues in positive trials during 1st half",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_positive_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### negative trials

```{r eval=FALSE}
data <- df_gng_glmm %>% filter(win_maintain == 0) %>% filter(trial_num <= 15)
print("Glancing each id: ")
sort(table(data$id))

mod2_neg <- model_fun("go", predictors, data)
summary(mod2_neg)
```

```{r eval=FALSE}
(plot_model(mod2_neg, type="eff",
            terms=c("trial_num", "go_str"), 
            title = "MIA: Learning of Go/NoGo cues in negative trials during 1st half",
            axis.title = c("Trial Number", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_action_learning_negative_1st_half.png"), width = 15, height = 10, units = "cm")
```

##### whether the learning of **Pos and Neg feedback** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num <= 15)
random_structure = "(1 + val_str + trial_num| id)"
predictors = c("val_str*QUIC*trial_num", covariates, random_structure)
mod2_val <- model_fun("go", predictors, data)
summary(mod2_val)
# sjPlot::tab_model(mod2_val)
```

```{r eval=FALSE}
# inf_mod2 <- influence(mod2_val, "id", maxfun=100)
# infIndexPlot(inf_mod2)
# plot((dfbetas(inf_mod2)[, "val_strpositive:QUIC:trial_num"]))
# 
# mod2_val.1 <- update(mod2_val, subset = id != c('2028', '2018')) # check deleting ids with high cook's distance
# inf_mod2.1 <- influence(mod2_val.1, "id", maxfun=100)
# infIndexPlot(inf_mod2.1)
# compareCoefs(mod2_val, mod2_val.1)
# 
# dfbeta(inf_mod2)
# dfbetas(inf_mod2)
```

```{r eval=FALSE}
# (plot_model(mod2_val, type="eff",
#             terms=c("QUIC", "val_str", "trial_num [5, 10, 15]"), 
#             title = "MIA: Learning of Pos/Neg cues in 1st half",
#             axis.title = c("Unpredictability (Standardized)", "% Go"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# # + ylim(0.3,1)
# ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")

(plot_model(mod2_val, type="eff",
            terms=c("QUIC", "val_str"), 
            title = "MIA: Learning of Pos/Neg cues in 1st half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")
```

## In the second half of the task

##### whether the learning of **go and nogo cues** vary with unpredictability?

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num > 15)
random_structure = "(1 + go_str + trial_num| id)"
predictors = c("go_str*QUIC*trial_num", covariates, random_structure)
mod3 <- model_fun("go", predictors, data)
summary(mod3)
# sjPlot::tab_model(mod3)
```

##### whether the learning of **Pos and Neg feedback** vary with unpredictability

```{r eval=FALSE}
data = subset(df_gng_glmm, trial_num > 15)
random_structure = "(1 + val_str + trial_num| id)"
predictors = c("val_str*QUIC*trial_num", covariates, random_structure)
mod3_val <- model_fun("go", predictors, data)
summary(mod3_val)
# sjPlot::tab_model(mod3_val)
```

```{r eval=FALSE}
# (plot_model(mod2_val, type="eff",
#             terms=c("QUIC", "val_str", "trial_num [5, 10, 15]"), 
#             title = "MIA: Learning of Pos/Neg cues in 1st half",
#             axis.title = c("Unpredictability (Standardized)", "% Go"),
#             show.data = FALSE, jitter= NULL, line.size = 1)) 
# # + ylim(0.3,1)
# ggsave(filename = file.path(plots_dir,"MIA_valence_learning_1st_half.png"), width = 15, height = 10, units = "cm")

(plot_model(mod3_val, type="eff",
            terms=c("QUIC", "val_str", "trial_num [20, 25, 30]"), 
            title = "MIA: Learning of Pos/Neg cues in 2nd half",
            axis.title = c("Unpredictability (Standardized)", "% Go"),
            show.data = FALSE, jitter= NULL, line.size = 1)) 
# + ylim(0.3,1)
ggsave(filename = file.path(plots_dir,"MIA_valence_learning_2nd_half.png"), width = 15, height = 10, units = "cm")
```

# Exploratory

### Cluster analyses

##### prep data

```{r eval=FALSE}
df_cluster <- gng_wide %>% left_join(., df_covar) %>% mutate_each_(funs(factor(.)),c("cluster_k2","cluster_k3","cluster_k4"))

table(df_cluster$cluster_k2)
table(df_cluster$cluster_k3)
table(df_cluster$cluster_k4)
##### things to consider: potential problem of uneven cluster?

# distribution of each variable across the 3 groups -- numeric
with(df_cluster, do.call(rbind, 
                         tapply(QUIC, cluster_k3, 
                                function(x) c(M = mean(x, na.rm = TRUE), SD = sd(x, na.rm = TRUE)))))

# distribution of each variable across the 3 groups -- histogram
ggplot(df_cluster, aes(x = QUIC)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .) # group 2 seems to have the most QUIC score
ggplot(df_cluster, aes(x = Perceived_stress)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = Digit_span)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = conflict_total)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)
ggplot(df_cluster, aes(x = Family_income)) +
  geom_histogram(position="identity") +
  facet_grid(cluster_k3 ~ .)

############ experimenting plotting codes ############
hist_fun <- function(var, cluster) {
  p <- ggplot(df_cluster, aes(x = get(var))) +
    geom_histogram(position="identity") +
    facet_grid(get(cluster) ~ .)
  return(p)
}

vars <- c("QUIC","Perceived_stress","Digit_span","Family_income","conflict_total")
clusters <- c("cluster_k2","cluster_k3","cluster_k4")
list <- mapply(hist_fun, vars, clusters) # look for how to show the plots as the codes below
```

##### multinomial regression

This analysis uses unpredictability and other covariates (continuous variables) to predict the chance of being in each clusters (nominal variable). Results show that none of the predictors were significant. \*refer to this source: <https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/>

```{r eval=FALSE}
df_cluster$cluster_k2_new <- relevel(df_cluster$cluster_k2, ref = "1")
df_cluster$cluster_k3_new <- relevel(df_cluster$cluster_k3, ref = "1")
df_cluster$cluster_k4_new <- relevel(df_cluster$cluster_k4, ref = "2")

fit2 <- multinom(cluster_k2_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit3 <- multinom(cluster_k3_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit4 <- multinom(cluster_k4_new ~ QUIC + Digit_span + Family_income, data = df_cluster)

tbl_regression(fit2, exp = TRUE)
tbl_regression(fit3, exp = TRUE)
tbl_regression(fit4, exp = TRUE)
```

```{r eval=FALSE}
df_cluster$cluster_k2_new <- relevel(df_cluster$cluster_k2, ref = "1")
df_cluster$cluster_k3_new <- relevel(df_cluster$cluster_k3, ref = "2")
df_cluster$cluster_k4_new <- relevel(df_cluster$cluster_k4, ref = "4")

fit2 <- multinom(cluster_k2_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit3 <- multinom(cluster_k3_new ~ QUIC + Digit_span + Family_income, data = df_cluster)
fit4 <- multinom(cluster_k4_new ~ QUIC + Digit_span + Family_income, data = df_cluster)

tbl_regression(fit2, exp = TRUE)
tbl_regression(fit3, exp = TRUE)
tbl_regression(fit4, exp = TRUE)
```